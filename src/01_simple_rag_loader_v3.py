# (ë‹¨ë½ë³´ì¡´ + í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜í˜• + ë©”ëª¨ë¦¬ ì´ˆê¸°í™”)
import os
import chromadb
from pathlib import Path
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# 1. ê²½ë¡œ ë° ì„¤ì •
TXT_DIR = Path(r"C:/Users/USER/rag/src/data/text_converted")
DB_PATH = r"C:/Users/USER/rag/src/data/chroma_db"
COLLECTION_NAME = "indonesia_pdt_docs"
OPENAI_API_KEY = "YOUR_API_KEY"

def initialize_and_load():
    # 2. ê¸°ì¡´ DB í´ë”ê°€ ìˆë‹¤ë©´ ì‚­ì œ (ì™„ì „ ì´ˆê¸°í™”)
    import shutil
    if os.path.exists(DB_PATH):
        print(f"ğŸ—‘ï¸ ê¸°ì¡´ DB ì‚­ì œ ì¤‘: {DB_PATH}")
        shutil.rmtree(DB_PATH)

    # 3. ì„ë² ë”© ëª¨ë¸ ë° í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„° ì„¤ì •
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, 
        chunk_overlap=100,
        separators=["\n\n", "\n", " ", ""]
    )

    # 4. íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    all_files = list(TXT_DIR.glob("*.txt"))
    print(f"ğŸš€ ì´ {len(all_files)}ê°œ íŒŒì¼ ë¡œë“œ ì‹œì‘...")

    # 5. ë°°ì¹˜ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ë³´í˜¸)
    batch_size = 10 
    for i in range(0, len(all_files), batch_size):
        batch_files = all_files[i : i + batch_size]
        documents = []
        metadatas = []

        for file_path in batch_files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    chunks = text_splitter.split_text(content)
                    
                    for chunk in chunks:
                        documents.append(chunk)
                        metadatas.append({"source": file_path.name})
            except Exception as e:
                print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({file_path.name}): {e}")

        # DBì— ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¶”ê°€ ë° ì €ì¥
        if documents:
            vector_db = Chroma.from_texts(
                texts=documents,
                embedding=embeddings,
                metadatas=metadatas,
                persist_directory=DB_PATH,
                collection_name=COLLECTION_NAME
            )
            print(f"âœ… ë°°ì¹˜ ì™„ë£Œ: {i + len(batch_files)} / {len(all_files)}")

    print(f"ğŸ ëª¨ë“  ë°ì´í„°ê°€ {DB_PATH}ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    initialize_and_load()
