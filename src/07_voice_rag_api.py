import os
import uvicorn
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from faster_whisper import WhisperModel
import io

from alias_map import clean_and_refine

# 1. ì´ˆê¸°í™”
DB_PATH = "./chroma_db"
COLLECTION_NAME = "project_docs"
app = FastAPI(title="Voice/Text Hybrid RAG API")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# RAG ì—”ì§„ & Whisper ëª¨ë¸ ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vector_db = Chroma(
    persist_directory=DB_PATH,
    embedding_function=embeddings,
    collection_name=COLLECTION_NAME
)
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# Whisper ëª¨ë¸ ë¡œë“œ (CPU ìµœì í™” ë²„ì „)
print("â³ Whisper STT ì—”ì§„ ë¡œë”© ì¤‘...")
stt_model = WhisperModel("base", device="cpu", compute_type="int8")
print("âœ… ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ")

# 2. ë°ì´í„° ëª¨ë¸
class ChatRequest(BaseModel):
    message: str

# 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (ê³µí†µ ê²€ìƒ‰ í•¨ìˆ˜)
def perform_rag_search(query: str):
    refined_query = clean_and_refine(query)
    docs = vector_db.similarity_search(refined_query, k=5)
    context = "\n".join([d.page_content for d in docs])
    sources = list(set([d.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ") for d in docs]))
    
    prompt = f"ë‹¤ìŒ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {refined_query}"
    response = llm.invoke(prompt)
    
    return {
        "refined_query": refined_query,
        "answer": response.content,
        "sources": sources
    }

# 4. ì—”ë“œí¬ì¸íŠ¸: í…ìŠ¤íŠ¸ ì§ˆì˜
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    return perform_rag_search(request.message)

# 5. ì—”ë“œí¬ì¸íŠ¸: ìŒì„± ì§ˆì˜ (Audio -> STT -> RAG)
@app.post("/voice")
async def voice_endpoint(file: UploadFile = File(...)):
    try:
        # ì˜¤ë””ì˜¤ íŒŒì¼ ë©”ëª¨ë¦¬ë¡œ ì½ê¸°
        audio_bytes = await file.read()
        audio_file = io.BytesIO(audio_bytes)
        
        # STT ë³€í™˜ (í•œêµ­ì–´ ì§€ì •)
        segments, info = stt_model.transcribe(audio_file, beam_size=5, language="ko")
        voice_text = " ".join([segment.text for segment in segments])
        
        print(f"ğŸ™ï¸ ì¸ì‹ëœ ìŒì„±: {voice_text}")
        
        # RAG ê²€ìƒ‰ ì‹¤í–‰
        result = perform_rag_search(voice_text)
        result["original_voice_text"] = voice_text
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
