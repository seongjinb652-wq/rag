import os
import uvicorn
import io
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from faster_whisper import WhisperModel

# ì™¸ë¶€ ì‚¬ì „ íŒŒì¼ì—ì„œ í•¨ìˆ˜ ë¡œë“œ
from alias_map import clean_and_refine

# 1. ì´ˆê¸°í™” ë° ì„¤ì •
DB_PATH = "./chroma_db"
COLLECTION_NAME = "project_docs"
app = FastAPI(title="FS Voice RAG System (large-v3)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# RAG ì»´í¬ë„ŒíŠ¸ ë¡œë“œ
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vector_db = Chroma(
    persist_directory=DB_PATH,
    embedding_function=embeddings,
    collection_name=COLLECTION_NAME
)
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# Whisper Large-v3 ëª¨ë¸ ë¡œë“œ (i7-14700 / 32GB RAM ìµœì í™”)
print("â³ Whisper STT ì—”ì§„(Large-v3) ë¡œë”© ì¤‘... (ì•½ 3GB)")
stt_model = WhisperModel("large-v3", device="cpu", compute_type="int8")

print("âœ… ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ")

# 2. ê³µí†µ ê²€ìƒ‰ ë¡œì§
def perform_rag_search(query: str):
    refined_query = clean_and_refine(query)
    print(f"ğŸ” [ìµœì¢… êµì • ì¿¼ë¦¬]: {refined_query}")
    
    docs = vector_db.similarity_search(refined_query, k=5)
    
    context_list = []
    sources = []
    root_folder_name = "@@@ì¸ë„ë„¤ì‹œì•„PDTì•”ì„¼í„°FS"
    
    for d in docs:
        content = d.page_content
        
        # 1. ë³¸ë¬¸ ì•ˆì— "Source:"ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if "Source:" in content:
            # Source: ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì„ ì •í™•íˆ ì°¾ì•„ëƒ„
            lines = content.split('\n')
            source_line = ""
            actual_body = []
            
            for line in lines:
                if line.startswith("Source:"):
                    source_line = line.replace("Source:", "").strip()
                elif line.strip() == "---": # ì ˆì·¨ì„  ì œì™¸
                    continue
                else:
                    actual_body.append(line)
            
            # ê²½ë¡œ ê°„ì†Œí™” ì²˜ë¦¬
            if source_line:
                if root_folder_name in source_line:
                    display_path = source_line.split(root_folder_name)[-1].lstrip('\\')
                else:
                    display_path = os.path.basename(source_line)
                sources.append(display_path)
            
            context_list.append("\n".join(actual_body))
        else:
            # Source ë¬¸êµ¬ê°€ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì°¸ì¡°
            context_list.append(content)
            sources.append(d.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"))
    
    sources = list(set([s for s in sources if s])) # ë¹ˆ ê°’ ì œì™¸ ë° ì¤‘ë³µ ì œê±°
    context = "\n".join(context_list)
    
    prompt = f"ë‹¤ìŒ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {refined_query}"
    response = llm.invoke(prompt)
    
    return {
        "original_text": query,
        "refined_query": refined_query,
        "answer": response.content,
        "sources": sources
    }
# 3. API ì—”ë“œí¬ì¸íŠ¸
class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
async def chat_text(request: ChatRequest):
    return perform_rag_search(request.message)

@app.post("/voice")
async def chat_voice(file: UploadFile = File(...)):
    try:
        audio_bytes = await file.read()
        audio_file = io.BytesIO(audio_bytes)
        
        # Whisper ë³€í™˜ (large-v3)
        segments, info = stt_model.transcribe(audio_file, beam_size=5, language="ko")
        voice_text = " ".join([segment.text for segment in segments])
        
        print(f"ğŸ™ï¸ [STT ì¸ì‹]: {voice_text}")
        return perform_rag_search(voice_text)
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    # workers=1ì„ ì§€ì •í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ê°€ ê¼¬ì´ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    uvicorn.run(app, host="0.0.0.0", port=8000, workers=1)
