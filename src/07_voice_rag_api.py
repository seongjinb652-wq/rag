import os
import uvicorn
import io
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from faster_whisper import WhisperModel

# ì™¸ë¶€ ì‚¬ì „ íŒŒì¼ì—ì„œ í•¨ìˆ˜ ë¡œë“œ
from alias_map import clean_and_refine

# 1. ì´ˆê¸°í™” ë° ì„¤ì •
DB_PATH = "./chroma_db"
COLLECTION_NAME = "project_docs"
app = FastAPI(title="FS Voice RAG System (large-v3)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# RAG ì»´í¬ë„ŒíŠ¸ ë¡œë“œ
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vector_db = Chroma(
    persist_directory=DB_PATH,
    embedding_function=embeddings,
    collection_name=COLLECTION_NAME
)
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# Whisper Large-v3 ëª¨ë¸ ë¡œë“œ (i7-14700 / 32GB RAM ìµœì í™”)
print("â³ Whisper STT ì—”ì§„(Large-v3) ë¡œë”© ì¤‘... (ì•½ 3GB)")
stt_model = WhisperModel("large-v3", device="cpu", compute_type="int8")

print("âœ… ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ")

# 2. ê³µí†µ ê²€ìƒ‰ ë¡œì§
def perform_rag_search(query: str):
    refined_query = clean_and_refine(query)
    print(f"ğŸ” [ìµœì¢… êµì • ì¿¼ë¦¬]: {refined_query}")
    
    docs = vector_db.similarity_search(refined_query, k=5)
    
    context_list = []
    sources = []
    root_folder_name = "@@@ì¸ë„ë„¤ì‹œì•„PDTì•”ì„¼í„°FS"
    
    for d in docs:
        content = d.page_content
        
        # 1. ë³¸ë¬¸ ì•ˆì— "Source:"ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if "Source:" in content:
            lines = content.split('\n')
            source_line = ""
            actual_body = []
            
            for line in lines:
                if line.startswith("Source:"):
                    source_line = line.replace("Source:", "").strip()
                # ìˆ˜ì •: í•˜ì´í”ˆì´ ì—¬ëŸ¬ ê°œ ìˆëŠ” êµ¬ë¶„ì„ (v4ìš©)ì´ë‚˜ '---'ë¥¼ ëª¨ë‘ ê±´ë„ˆëœ€
                elif line.strip().startswith("---"): 
                    continue
                else:
                    actual_body.append(line)
            
            # ê²½ë¡œ ê°„ì†Œí™” ì²˜ë¦¬
            if source_line:
                # v4ì˜ ìŠ¬ë˜ì‹œ(/) ê²½ë¡œì™€ v3ì˜ ì—­ìŠ¬ë˜ì‹œ(\) ê²½ë¡œ ëª¨ë‘ ëŒ€ì‘
                source_line = source_line.replace('\\', '/')
                target_root = root_folder_name.replace('\\', '/')
                
                if target_root in source_line:
                    # Root ì´í›„ì˜ ê²½ë¡œë§Œ ì¶”ì¶œ
                    display_path = source_line.split(target_root)[-1].lstrip('/')
                else:
                    display_path = os.path.basename(source_line)
                
                sources.append(display_path)
            
            context_list.append("\n".join(actual_body))
        else:
            # Source ë¬¸êµ¬ê°€ ì—†ëŠ” ì˜›ë‚  ë°ì´í„° ì²˜ë¦¬
            context_list.append(content)
            raw_src = d.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ")
            sources.append(os.path.basename(raw_src))
    
    # [ê²€ì¦ í¬ì¸íŠ¸ 1] ì¤‘ë³µ ì œê±° ë° ì •ë ¬ (ê°€ì¥ ê¹”ë”í•œ ìµœì¢… í˜•íƒœ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê¸°)
    sources = sorted(list(set([s for s in sources if s]))) 
    
    # [ê²€ì¦ í¬ì¸íŠ¸ 2] ì»¨í…ìŠ¤íŠ¸ ê²°í•©
    context = "\n\n".join(context_list) # ë¬¸ì„œ ê°„ êµ¬ë¶„ì„ ìœ„í•´ \n\n ì¶”ì²œ
    
    # [ê²€ì¦ í¬ì¸íŠ¸ 3] í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë° LLM í˜¸ì¶œ
    prompt = f"ë‹¤ìŒ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {refined_query}"
    
    try:
        response = llm.invoke(prompt)
        answer = response.content
    except Exception as e:
        logger.error(f"LLM í˜¸ì¶œ ì—ëŸ¬: {e}")
        answer = "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    # [ìµœì¢… ê²°ê³¼ ë°˜í™˜]
    return {
        "original_text": query,
        "refined_query": refined_query,
        "answer": answer,
        "sources": sources  # ì´ì œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì •í™•íˆ ë‚˜ê°‘ë‹ˆë‹¤.
    }
# 3. API ì—”ë“œí¬ì¸íŠ¸
class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
async def chat_text(request: ChatRequest):
    return perform_rag_search(request.message)

@app.post("/voice")
async def chat_voice(file: UploadFile = File(...)):
    try:
        audio_bytes = await file.read()
        audio_file = io.BytesIO(audio_bytes)
        
        # Whisper ë³€í™˜ (large-v3)
        segments, info = stt_model.transcribe(audio_file, beam_size=5, language="ko")
        voice_text = " ".join([segment.text for segment in segments])
        
        print(f"ğŸ™ï¸ [STT ì¸ì‹]: {voice_text}")
        return perform_rag_search(voice_text)
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    # workers=1ì„ ì§€ì •í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ê°€ ê¼¬ì´ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    uvicorn.run(app, host="0.0.0.0", port=8000, workers=1)
