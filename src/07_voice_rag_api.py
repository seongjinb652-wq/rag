import os
import uvicorn
import io
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from faster_whisper import WhisperModel

from alias_map import clean_and_refine

# 1. ì´ˆê¸°í™” ë° ì„¤ì •
DB_PATH = "./chroma_db"
COLLECTION_NAME = "project_docs"
app = FastAPI(title="FS Voice RAG System (Medium)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# RAG ì»´í¬ë„ŒíŠ¸ ë¡œë“œ
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vector_db = Chroma(
    persist_directory=DB_PATH,
    embedding_function=embeddings,
    collection_name=COLLECTION_NAME
)
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# Whisper Medium ëª¨ë¸ ë¡œë“œ (ì¸ì‹ë¥  ëŒ€í­ í–¥ìƒ)
print("â³ Whisper STT ì—”ì§„(Medium) ë¡œë”© ì¤‘... (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œ)")
stt_model = WhisperModel("medium", device="cpu", compute_type="int8")
print("âœ… ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ")

# 2. ê³µí†µ ê²€ìƒ‰ ë¡œì§
def perform_rag_search(query: str):
    refined_query = clean_and_refine(query)
    
    # ê²€ìƒ‰ (k=5)
    docs = vector_db.similarity_search(refined_query, k=5)
    context = "\n".join([d.page_content for d in docs])
    sources = list(set([d.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ") for d in docs]))
    
    # ë‹µë³€ ìƒì„±
    prompt = f"ë‹¤ìŒ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {refined_query}"
    response = llm.invoke(prompt)
    
    return {
        "original_text": query,
        "refined_query": refined_query,
        "answer": response.content,
        "sources": sources
    }

# 3. API ì—”ë“œí¬ì¸íŠ¸
class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
async def chat_text(request: ChatRequest):
    return perform_rag_search(request.message)

@app.post("/voice")
async def chat_voice(file: UploadFile = File(...)):
    try:
        audio_bytes = await file.read()
        audio_file = io.BytesIO(audio_bytes)
        
        # Whisper ë³€í™˜
        segments, info = stt_model.transcribe(audio_file, beam_size=5, language="ko")
        voice_text = " ".join([segment.text for segment in segments])
        
        print(f"ğŸ™ï¸ [STT ì¸ì‹]: {voice_text}")
        return perform_rag_search(voice_text)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
