import os
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from config import Settings # ì¤‘ì•™ ì„¤ì • ì°¸ì¡°

def search_test():
    # 1. DB ë° ëª¨ë¸ ì„¤ì • (ê¸°ì¡´ ê°’ ì£¼ì„ ë³´ì¡´)
    # DB_PATH = r"C:/Users/USER/rag/src/data/chroma_db"
    db_path = str(Settings.CHROMA_DB_PATH)
    # COLLECTION_NAME = "indonesia_pdt_docs"
    collection_name = Settings.CHROMA_COLLECTION_NAME
    # embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    embeddings = OpenAIEmbeddings(model=Settings.EMBEDDING_MODEL)

    # 2. ë²¡í„° DB ì—°ê²°
    vector_db = Chroma(
        persist_directory=db_path,
        embedding_function=embeddings,
        collection_name=collection_name
    )

    # 3. ê²€ìƒ‰ ë° LLM ì„¤ì • (ê¸°ì¡´ ê°’ ì£¼ì„ ë³´ì¡´)
    # llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
    llm = ChatOpenAI(model_name=Settings.OPENAI_MODEL, temperature=0)
    
    query = "ì¸ë„ë„¤ì‹œì•„ PDT ì•”ì„¼í„° ê±´ë¦½ ì˜ˆì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?" 
    print(f"\nğŸ” ì§ˆë¬¸: {query}")

    # 4. ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰ (Kê°’ Settings ì—°ë™)
    # docs = vector_db.similarity_search(query, k=5)
    docs = vector_db.similarity_search(query, k=Settings.VECTOR_SEARCH_K)

    print(f"\nğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")
    print("-" * 50)

    for i, doc in enumerate(docs, 1):
        # [ì§€ì‹œì‚¬í•­] META_SOURCE_KEYë¥¼ í™œìš©í•œ ì¶œì²˜ ì¶œë ¥
        # source = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ")
        source = doc.metadata.get(Settings.META_SOURCE_KEY, "ì•Œ ìˆ˜ ì—†ìŒ")
        
        print(f"[{i}] ì¶œì²˜: {os.path.basename(source)}")
        print(f"ë‚´ìš©: {doc.page_content[:150]}...")
        print("-" * 50)

    # 5. LLM ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸
    context = "\n\n".join([d.page_content for d in docs])
    prompt = f"ë‹¤ìŒ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {query}"
    
    response = llm.invoke(prompt)
    print(f"\nğŸ¤– LLM ë‹µë³€:\n{response.content}")

if __name__ == "__main__":
    search_test()
